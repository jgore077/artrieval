Epoch 1/50, Batch: 1/325, Loss: 3.5869, Training Acc: 0.5000, Training F1: 0.4288
Epoch 1/50, Batch: 2/325, Loss: 3.5973, Training Acc: 0.4750, Training F1: 0.3912
Epoch 1/50, Batch: 3/325, Loss: 3.5880, Training Acc: 0.6250, Training F1: 0.5450
Epoch 1/50, Batch: 4/325, Loss: 3.5811, Training Acc: 0.4750, Training F1: 0.3845
Epoch 1/50, Batch: 5/325, Loss: 3.6219, Training Acc: 0.5250, Training F1: 0.4475
Epoch 1/50, Batch: 6/325, Loss: 3.5582, Training Acc: 0.6500, Training F1: 0.5912
Epoch 1/50, Batch: 7/325, Loss: 3.6099, Training Acc: 0.6250, Training F1: 0.5500
Epoch 1/50, Batch: 8/325, Loss: 3.5776, Training Acc: 0.4250, Training F1: 0.3392
Epoch 1/50, Batch: 9/325, Loss: 3.4931, Training Acc: 0.5000, Training F1: 0.3947
Epoch 1/50, Batch: 10/325, Loss: 3.6047, Training Acc: 0.6000, Training F1: 0.5196
Epoch 1/50, Batch: 11/325, Loss: 3.5631, Training Acc: 0.4000, Training F1: 0.2850
Epoch 1/50, Batch: 12/325, Loss: 3.6127, Training Acc: 0.5000, Training F1: 0.4310
Epoch 1/50, Batch: 13/325, Loss: 3.5668, Training Acc: 0.4250, Training F1: 0.3183
Epoch 1/50, Batch: 14/325, Loss: 3.5938, Training Acc: 0.4750, Training F1: 0.3617
Epoch 1/50, Batch: 15/325, Loss: 3.6221, Training Acc: 0.5750, Training F1: 0.4988
Epoch 1/50, Batch: 16/325, Loss: 3.6042, Training Acc: 0.4000, Training F1: 0.3201
Epoch 1/50, Batch: 17/325, Loss: 3.5760, Training Acc: 0.5500, Training F1: 0.4833
Epoch 1/50, Batch: 18/325, Loss: 3.6084, Training Acc: 0.5750, Training F1: 0.4950
Epoch 1/50, Batch: 19/325, Loss: 3.6149, Training Acc: 0.4750, Training F1: 0.4208
Epoch 1/50, Batch: 20/325, Loss: 3.5668, Training Acc: 0.4750, Training F1: 0.3829
Epoch 1/50, Batch: 21/325, Loss: 3.5880, Training Acc: 0.3750, Training F1: 0.3134
Epoch 1/50, Batch: 22/325, Loss: 3.5919, Training Acc: 0.4500, Training F1: 0.3713
Epoch 1/50, Batch: 23/325, Loss: 3.5530, Training Acc: 0.5750, Training F1: 0.5100
Epoch 1/50, Batch: 24/325, Loss: 3.6234, Training Acc: 0.6750, Training F1: 0.6000
Epoch 1/50, Batch: 25/325, Loss: 3.5710, Training Acc: 0.6500, Training F1: 0.5847
Epoch 1/50, Batch: 26/325, Loss: 3.5563, Training Acc: 0.5000, Training F1: 0.4058
Epoch 1/50, Batch: 27/325, Loss: 3.5752, Training Acc: 0.5750, Training F1: 0.5005
Epoch 1/50, Batch: 28/325, Loss: 3.5909, Training Acc: 0.5250, Training F1: 0.4479
Epoch 1/50, Batch: 29/325, Loss: 3.6050, Training Acc: 0.5250, Training F1: 0.4667
Epoch 1/50, Batch: 30/325, Loss: 3.6046, Training Acc: 0.4500, Training F1: 0.3846
Epoch 1/50, Batch: 31/325, Loss: 3.6207, Training Acc: 0.5250, Training F1: 0.4367
Epoch 1/50, Batch: 32/325, Loss: 3.6322, Training Acc: 0.4750, Training F1: 0.3792
Epoch 1/50, Batch: 33/325, Loss: 3.6404, Training Acc: 0.4500, Training F1: 0.3775
Epoch 1/50, Batch: 34/325, Loss: 3.5934, Training Acc: 0.7000, Training F1: 0.6292
Epoch 1/50, Batch: 35/325, Loss: 3.5657, Training Acc: 0.6750, Training F1: 0.6017
Epoch 1/50, Batch: 36/325, Loss: 3.5431, Training Acc: 0.5500, Training F1: 0.4597
Epoch 1/50, Batch: 37/325, Loss: 3.5945, Training Acc: 0.5000, Training F1: 0.4142
Epoch 1/50, Batch: 38/325, Loss: 3.5778, Training Acc: 0.5000, Training F1: 0.4460
Epoch 1/50, Batch: 39/325, Loss: 3.5922, Training Acc: 0.5500, Training F1: 0.4492
Epoch 1/50, Batch: 40/325, Loss: 3.6208, Training Acc: 0.4250, Training F1: 0.3467
Epoch 1/50, Batch: 41/325, Loss: 3.5660, Training Acc: 0.6750, Training F1: 0.6121
Epoch 1/50, Batch: 42/325, Loss: 3.5469, Training Acc: 0.6500, Training F1: 0.5571
Epoch 1/50, Batch: 43/325, Loss: 3.6208, Training Acc: 0.4500, Training F1: 0.3785
Epoch 1/50, Batch: 44/325, Loss: 3.6156, Training Acc: 0.5750, Training F1: 0.5017
Epoch 1/50, Batch: 45/325, Loss: 3.6163, Training Acc: 0.6000, Training F1: 0.5130
Epoch 1/50, Batch: 46/325, Loss: 3.6116, Training Acc: 0.5250, Training F1: 0.4142
Epoch 1/50, Batch: 47/325, Loss: 3.5833, Training Acc: 0.5250, Training F1: 0.4296
Epoch 1/50, Batch: 48/325, Loss: 3.6208, Training Acc: 0.4250, Training F1: 0.3308
Epoch 1/50, Batch: 49/325, Loss: 3.5987, Training Acc: 0.5000, Training F1: 0.3983
Epoch 1/50, Batch: 50/325, Loss: 3.5960, Training Acc: 0.5000, Training F1: 0.4410
Epoch 1/50, Batch: 51/325, Loss: 3.6312, Training Acc: 0.5750, Training F1: 0.4892
Epoch 1/50, Batch: 52/325, Loss: 3.5592, Training Acc: 0.5500, Training F1: 0.4771
Epoch 1/50, Batch: 53/325, Loss: 3.6106, Training Acc: 0.6500, Training F1: 0.5713
Epoch 1/50, Batch: 54/325, Loss: 3.5710, Training Acc: 0.5750, Training F1: 0.5058
Epoch 1/50, Batch: 55/325, Loss: 3.5829, Training Acc: 0.5250, Training F1: 0.4222
Epoch 1/50, Batch: 56/325, Loss: 3.6078, Training Acc: 0.6750, Training F1: 0.6121
Epoch 1/50, Batch: 57/325, Loss: 3.5797, Training Acc: 0.4750, Training F1: 0.4142
Epoch 1/50, Batch: 58/325, Loss: 3.5696, Training Acc: 0.6750, Training F1: 0.6100
Epoch 1/50, Batch: 59/325, Loss: 3.5161, Training Acc: 0.6250, Training F1: 0.5433
Epoch 1/50, Batch: 60/325, Loss: 3.5852, Training Acc: 0.5500, Training F1: 0.4517
Epoch 1/50, Batch: 61/325, Loss: 3.5808, Training Acc: 0.6250, Training F1: 0.5292
Epoch 1/50, Batch: 62/325, Loss: 3.6243, Training Acc: 0.5250, Training F1: 0.4667
Epoch 1/50, Batch: 63/325, Loss: 3.5951, Training Acc: 0.6250, Training F1: 0.5533
Epoch 1/50, Batch: 64/325, Loss: 3.5968, Training Acc: 0.6500, Training F1: 0.5625
Epoch 1/50, Batch: 65/325, Loss: 3.6220, Training Acc: 0.5000, Training F1: 0.4229
Epoch 1/50, Batch: 66/325, Loss: 3.6141, Training Acc: 0.5250, Training F1: 0.4408
Epoch 1/50, Batch: 67/325, Loss: 3.5920, Training Acc: 0.6500, Training F1: 0.5658
Epoch 1/50, Batch: 68/325, Loss: 3.5711, Training Acc: 0.6000, Training F1: 0.5296
Epoch 1/50, Batch: 69/325, Loss: 3.6189, Training Acc: 0.5000, Training F1: 0.4183
Epoch 1/50, Batch: 70/325, Loss: 3.6075, Training Acc: 0.5000, Training F1: 0.4114
Epoch 1/50, Batch: 71/325, Loss: 3.6077, Training Acc: 0.4500, Training F1: 0.3321
Epoch 1/50, Batch: 72/325, Loss: 3.6055, Training Acc: 0.5750, Training F1: 0.5017
Epoch 1/50, Batch: 73/325, Loss: 3.5982, Training Acc: 0.4250, Training F1: 0.3033
Epoch 1/50, Batch: 74/325, Loss: 3.6211, Training Acc: 0.4250, Training F1: 0.3281
Epoch 1/50, Batch: 75/325, Loss: 3.5874, Training Acc: 0.4750, Training F1: 0.4030
Epoch 1/50, Batch: 76/325, Loss: 3.5950, Training Acc: 0.5500, Training F1: 0.4650
Epoch 1/50, Batch: 77/325, Loss: 3.6108, Training Acc: 0.5250, Training F1: 0.4267
Epoch 1/50, Batch: 78/325, Loss: 3.6015, Training Acc: 0.5000, Training F1: 0.4326
Epoch 1/50, Batch: 79/325, Loss: 3.6032, Training Acc: 0.4000, Training F1: 0.3155
Epoch 1/50, Batch: 80/325, Loss: 3.5857, Training Acc: 0.5750, Training F1: 0.4975
Epoch 1/50, Batch: 81/325, Loss: 3.5963, Training Acc: 0.4250, Training F1: 0.3363
Epoch 1/50, Batch: 82/325, Loss: 3.6150, Training Acc: 0.5500, Training F1: 0.4858
Epoch 1/50, Batch: 83/325, Loss: 3.5907, Training Acc: 0.6250, Training F1: 0.5558
Epoch 1/50, Batch: 84/325, Loss: 3.6095, Training Acc: 0.5250, Training F1: 0.4317
Epoch 1/50, Batch: 1/325, Loss: 3.5959, Training Acc: 0.5250, Training F1: 0.4375
Epoch 1/50, Batch: 2/325, Loss: 3.5852, Training Acc: 0.4500, Training F1: 0.3560
Epoch 1/50, Batch: 3/325, Loss: 3.6115, Training Acc: 0.5750, Training F1: 0.4938
Epoch 1/50, Batch: 4/325, Loss: 3.6069, Training Acc: 0.6000, Training F1: 0.5267
Epoch 1/50, Batch: 5/325, Loss: 3.6030, Training Acc: 0.5000, Training F1: 0.4088
Epoch 1/50, Batch: 6/325, Loss: 3.5189, Training Acc: 0.7000, Training F1: 0.6333
Epoch 1/50, Batch: 7/325, Loss: 3.6045, Training Acc: 0.5750, Training F1: 0.4758
Epoch 1/50, Batch: 8/325, Loss: 3.6162, Training Acc: 0.6250, Training F1: 0.5542
Epoch 1/50, Batch: 9/325, Loss: 3.5858, Training Acc: 0.4750, Training F1: 0.3881
Epoch 1/50, Batch: 10/325, Loss: 3.5919, Training Acc: 0.4750, Training F1: 0.3813
Epoch 1/50, Batch: 11/325, Loss: 3.6246, Training Acc: 0.5500, Training F1: 0.4630
Epoch 1/50, Batch: 12/325, Loss: 3.6362, Training Acc: 0.5000, Training F1: 0.3905
Epoch 1/50, Batch: 13/325, Loss: 3.6071, Training Acc: 0.3250, Training F1: 0.2420
Epoch 1/50, Batch: 14/325, Loss: 3.5865, Training Acc: 0.4500, Training F1: 0.3537
Epoch 1/50, Batch: 15/325, Loss: 3.5517, Training Acc: 0.4750, Training F1: 0.4113
Epoch 1/50, Batch: 16/325, Loss: 3.5553, Training Acc: 0.6000, Training F1: 0.4917
Epoch 1/50, Batch: 17/325, Loss: 3.5896, Training Acc: 0.4750, Training F1: 0.3646
Epoch 1/50, Batch: 18/325, Loss: 3.6259, Training Acc: 0.4750, Training F1: 0.3880
Epoch 1/50, Batch: 19/325, Loss: 3.6170, Training Acc: 0.5250, Training F1: 0.4042
Epoch 1/50, Batch: 20/325, Loss: 3.6335, Training Acc: 0.5000, Training F1: 0.4333
Epoch 1/50, Batch: 21/325, Loss: 3.5888, Training Acc: 0.5000, Training F1: 0.3821
Epoch 1/50, Batch: 22/325, Loss: 3.6120, Training Acc: 0.4750, Training F1: 0.3801
Epoch 1/50, Batch: 23/325, Loss: 3.5967, Training Acc: 0.6750, Training F1: 0.5958
Epoch 1/50, Batch: 24/325, Loss: 3.5948, Training Acc: 0.6000, Training F1: 0.5333
Epoch 1/50, Batch: 25/325, Loss: 3.5767, Training Acc: 0.5500, Training F1: 0.4475
Epoch 1/50, Batch: 26/325, Loss: 3.6341, Training Acc: 0.4500, Training F1: 0.4017
Epoch 1/50, Batch: 27/325, Loss: 3.5919, Training Acc: 0.5500, Training F1: 0.4589
Epoch 1/50, Batch: 28/325, Loss: 3.5964, Training Acc: 0.4250, Training F1: 0.3280
Epoch 1/50, Batch: 29/325, Loss: 3.5625, Training Acc: 0.5250, Training F1: 0.4342
Epoch 1/50, Batch: 30/325, Loss: 3.5559, Training Acc: 0.6750, Training F1: 0.5958
Epoch 1/50, Batch: 31/325, Loss: 3.6317, Training Acc: 0.5000, Training F1: 0.4389
Epoch 1/50, Batch: 32/325, Loss: 3.6024, Training Acc: 0.5000, Training F1: 0.3963
Epoch 1/50, Batch: 33/325, Loss: 3.5997, Training Acc: 0.5750, Training F1: 0.4792
Epoch 1/50, Batch: 34/325, Loss: 3.5585, Training Acc: 0.5250, Training F1: 0.4435
Epoch 1/50, Batch: 35/325, Loss: 3.6178, Training Acc: 0.4750, Training F1: 0.3905
Epoch 1/50, Batch: 36/325, Loss: 3.5337, Training Acc: 0.7250, Training F1: 0.6917
Epoch 1/50, Batch: 37/325, Loss: 3.5680, Training Acc: 0.5250, Training F1: 0.4155
Epoch 1/50, Batch: 38/325, Loss: 3.5963, Training Acc: 0.4000, Training F1: 0.2892
Epoch 1/50, Batch: 39/325, Loss: 3.6067, Training Acc: 0.5500, Training F1: 0.4571
Epoch 1/50, Batch: 40/325, Loss: 3.6046, Training Acc: 0.5750, Training F1: 0.4825
Epoch 1/50, Batch: 41/325, Loss: 3.5644, Training Acc: 0.3250, Training F1: 0.2200
Epoch 1/50, Batch: 42/325, Loss: 3.5546, Training Acc: 0.5500, Training F1: 0.4521
Epoch 1/50, Batch: 43/325, Loss: 3.5621, Training Acc: 0.6000, Training F1: 0.5042
Epoch 1/50, Batch: 44/325, Loss: 3.5892, Training Acc: 0.5250, Training F1: 0.4142
Epoch 1/50, Batch: 45/325, Loss: 3.5757, Training Acc: 0.5000, Training F1: 0.4151
Epoch 1/50, Batch: 46/325, Loss: 3.5631, Training Acc: 0.5750, Training F1: 0.4854
Epoch 1/50, Batch: 47/325, Loss: 3.5807, Training Acc: 0.4250, Training F1: 0.3321
Epoch 1/50, Batch: 48/325, Loss: 3.5967, Training Acc: 0.4250, Training F1: 0.3442
Epoch 1/50, Batch: 49/325, Loss: 3.5954, Training Acc: 0.5000, Training F1: 0.4313
Epoch 1/50, Batch: 50/325, Loss: 3.5774, Training Acc: 0.3750, Training F1: 0.2983
Epoch 1/50, Batch: 51/325, Loss: 3.5918, Training Acc: 0.5000, Training F1: 0.4342
